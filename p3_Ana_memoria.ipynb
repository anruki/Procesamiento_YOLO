{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anruki/Procesamiento_YOLO/blob/main/p3_Ana_memoria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# PROCESAMIENTO DE V√çDEO PARA EL CUIDADO DE CABALLOS\n",
        "---\n",
        "### ü§ì **Autores**: Ana Robledano y Miguel Egido\n",
        "### üì∏ **Asignatura**: Procesamiento Multimedia\n",
        "### üßë **Profesor**: Daniel Eusebio\n",
        "### üëÄ **Algoritmo**: You Only Look Once (YOLO)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aqSlGPj6gU5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. INTRODUCCI√ìN\n",
        "\n",
        "En este proyecto se estudian casos de uso del procesamiento de v√≠deo junto con inteligencia artificial en el mundo ecuestre.\n",
        "\n",
        "Se realizan las siguientes t√©cnicas:\n",
        "* __Preprocesamiento__: se aplican filtros, operaciones morfol√≥gicas,...\n",
        "* __Inteligencia Artificial__: YOLO para la detecci√≥n de caballos\n",
        "* __Preprocesamiento__: para extraer caracter√≠sticas de los caballos detectados (su posici√≥n y velocidad).\n",
        "\n",
        "El preprocesamiento facilita la tarea de reconocimiento de la IA y reduce la capacidad de computaci√≥n necesaria para la ejecuci√≥n del algoritmo YOLO.\n",
        "\n",
        "El papel del procesamiento multimedia en este proyecto es crear un ``pipeline`` que transforma el v√≠deo input para que pueda ser procesado por el algoritmo YOLO.\n",
        "\n"
      ],
      "metadata": {
        "id": "wthxeZYrXhh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1. Preprocesamiento"
      ],
      "metadata": {
        "id": "uKzO1w5rbKhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kdT9Br6_cw06"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hz6hIBGmcxE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2.Algoritmo You Only Look One (YOLO)\n"
      ],
      "metadata": {
        "id": "hnPNA7X1bOrC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El algoritmo You Only Look Once (YOLO), es un sistema de c√≥digo abierto para detecci√≥n de objetos en tiempo real, el cual hace uso de una √∫nica red neuronal convolucional para detectar objetos en im√°genes. Para su funcionamiento, la red neuronal divide la imagen en regiones, prediciendo cuadros de identificaci√≥n y probabilidades por cada regi√≥n; las cajas son ponderadas a partir de las probabilidades predichas. El algoritmo aprende representaciones generalizables de los objetos, permitiendo un bajo error de detecci√≥n para entradas nuevas, diferentes al conjunto de datos de entrenamiento.1\n",
        "\n",
        "El algoritmo base corre a 45 cuadros por segundo (FPS) sin procesamiento de lote en un GPU Titan X. Debido a sus caracter√≠sticas de procesamiento, el algoritmo es utilizado en aplicaciones de detecci√≥n de objetos en transmisi√≥n de video con retazo de se√±al menor a 25 milisegundos.2\n",
        "\n",
        "Arquitectura\n",
        "El modelo se implement√≥ como una red neuronal convolucional y fue evaluado en el set de datos para detecci√≥n de PASCAL VOC. Las capas convolucionales iniciales de la red se encargan de la extracci√≥n de caracter√≠sticas de la imagen, mientras que las capas de conexi√≥n completa predicen la probabilidad de salida y las coordenadas del objeto.\n",
        "\n",
        "La red tiene 24 capas convolucionales seguidas por 2 capas de conexi√≥n completa; esta hace uso de capas de reducci√≥n de 1x1 seguidas capas convolucionales de 3x3. El modelo Fast YOLO hace uso de una red neuronal de 9 capas. La salida final del modelo tensor de predicci√≥n de 7x7x30.3‚Äã\n",
        "\n",
        "\n",
        "Limitaciones\n",
        "El algoritmo delimita fuertes restricciones espaciales en los l√≠mites de la caja de predicci√≥n dado que cada celda predice √∫nicamente dos cajas y una clase; esto limita el n√∫mero de objetos que se pueden detectar, lo cual hace que el algoritmo se vea limitado en la detecci√≥n de objetos presentados en grupos.\n",
        "\n",
        "Presenta problemas en la generalizaci√≥n de objetos visualizados en distintas configuraciones, al igual que en el proceso de post procesamiento de errores, tratando todos los errores con el mismo nivel de importancia.4‚Äã"
      ],
      "metadata": {
        "id": "BpBpMiFBcRln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python ultralytics"
      ],
      "metadata": {
        "id": "otPAK63mgYad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfeb9153-1860-426f-cd7b-dea863aa7780"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.55-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.55-py3-none-any.whl (904 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m904.3/904.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.55 ultralytics-thop-2.0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "t6crU69DcZen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "280f1ca2-2d65-4fc5-c266-1de0060160ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ¬øPor qu√© Inteligencia Artificial?\n",
        "Aunque el uso de Inteligencia Artificial supone un coste adicional en el procesamiento multimedia, aporta mayor flexibilidad de escenarios.\n",
        "\n",
        "La detecci√≥n de caballos podr√≠a realizarse manualmente mediante funciones de clusterizaci√≥n que no utilizan IA. No obstante, este proyecto est√° enfocado en el cuidado de distintos tipos y tama√±os de caballos y otros animales. El modelo YOLO preentrenado permite la clasificaci√≥n efectiva de distintas clases de animales independientemente de un √°rea espec√≠fica.\n",
        "\n",
        "Concretamente para este proyecto nos centraremos en el procesamiento de v√≠deo para el cuidado de caballos. Con la colaboraci√≥n de H√≠pica Natur http://hipicamadrid.es/ que nos ha facilitado la recogida de v√≠deos en un entorno ganadero real."
      ],
      "metadata": {
        "id": "QzMiUIB7ePwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Aplicaci√≥n real\n",
        "\n",
        "A continuaci√≥n se muestra el procesamiento de v√≠deo de un caballo para su detecci√≥n mediante los apartados definidos anteriormente."
      ],
      "metadata": {
        "id": "lhBoZz4nbbgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importaci√≥n de librer√≠as y del v√≠deo"
      ],
      "metadata": {
        "id": "ZyxfP1Zsgbju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "ARkUQsnwgb7k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = 'sunday_vid.mov'\n",
        "cap = cv2.VideoCapture(video_path)"
      ],
      "metadata": {
        "id": "IiyN8-ZAdLWW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga del modelo `` YOLO V8 ``\n",
        "\n"
      ],
      "metadata": {
        "id": "ulMdrkCcdPIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load yolov8 model\n",
        "model = YOLO('yolov8n.pt')"
      ],
      "metadata": {
        "id": "ZCx9fmcxiMts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79907fae-6634-41e2-ce09-55dec2a13455"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.25M/6.25M [00:00<00:00, 53.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procesamiento del v√≠deo\n",
        "Mediante un bucle que recorre cada frame:"
      ],
      "metadata": {
        "id": "0BvU-rJVdbFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if video loaded successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "while True:\n",
        "    # Read frame\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"End of video or cannot fetch the frame.\")\n",
        "        break\n",
        "\n",
        "    # Detect and track objects\n",
        "    results = model.track(frame, persist=True)\n",
        "\n",
        "    # Plot results\n",
        "    frame_ = results[0].plot()  # Annotated frame\n",
        "\n",
        "    # Display the annotated frame\n",
        "    cv2.imshow('YOLOv8 Tracking', frame_)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
        "        break\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print('Video Processing Complete.')"
      ],
      "metadata": {
        "id": "H6lLVxvMdh-S"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicaci√≥n del c√≥digo** (..)"
      ],
      "metadata": {
        "id": "hxhHk8aRNwsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para un v√≠deo con la c√°mara no est√°tica y donde el caballo se acerca y aleja del plano, el algoritmo YOLO detecta con una precisi√≥n alta al caballo.\n",
        "\n",
        "\n",
        "El paso siguiente ser√° utilizar la posici√≥n del caballo para determinar si se escapa del cercado o no. El objetivo es crear un sistema que alerte cuando alg√∫n caballo escape del cercado, teniendo en cuenta que cuando lo saca una persona el sistema no debe activar ninguna alerta."
      ],
      "metadata": {
        "id": "21jzgmwyzEro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. POSICI√ìN - Sistema de alerta cuando un caballo escapa"
      ],
      "metadata": {
        "id": "wd1vorA32bl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una de las mayores preocupaciones de los ganaderos es el bienestar de sus animales. Aunque las instalaciones est√©n pensadas para el ganado, puede haber problemas t√©cnicos (como fallas en el sistema de cercado el√©ctrico) u otras situaciones impredecibles. https://www.youtube.com/watch?v=K1FPRo7hO7I\n",
        "\n",
        "Las consecuencias de que un animal se escape pueden ser fatales ya que si huyen hacia la carretera pueden provocar accidentes graves.\n",
        "\n",
        "Este proyecto busca automatizar la vigilancia, permitiendo a los ganaderos dedicarse a otras tareas o a descansar mientras el sistema vigila y alerta en caso de que un animal escape."
      ],
      "metadata": {
        "id": "ZkaGhM9E9ahk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para ello, se siguen los pasos anteriores (preprocesamiento y YOLO), a√±adiendo una ``regi√≥n de inter√©s`` de la que si el caballo sale, se cambiar√° el color de su ``bounding box`` y se activar√° una alerta.\n",
        "\n",
        "* La regi√≥n de inter√©s queda delimitada por una valla, cuya posici√≥n depender√° del plano de la c√°mara y la posici√≥n de la valla. Este paso no es automatizable, pero es sencillo de aplicar a cualquier escenario similar. - ``posibilidad de hacer interactivo``.\n",
        "* En un cercado puede haber m√°s de un caballo, a cada caballo se le asignar√° una etiqueta distinta, cuando un caballo escape se har√° una captura de pantalla del caballo que escap√≥ para que el due√±o pueda identificarlo rapidamente y se llevar√° un recuento del n¬∫ de caballos que escaparon. ``vista a futuro: posibilidad de hacer interactivo haciendo una etiqueta personalizada para cada caballo con su nombre``.\n",
        "* Cuando se identifique a una persona (por el algoritmo YOLO), no se activar√° ninguna alerta, ya que esto sugiere que la persona intencionalmente sac√≥ al caballo del cercado. Esta funci√≥n podr√≠a desactivarse para que siempre saltase la alarma (aunque haya personas) y evitar robos. - ``posibilidad de hacer interactivo``."
      ],
      "metadata": {
        "id": "hH-Z-4r74PQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar modelo YOLOv8\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Ruta del video de entrada\n",
        "video_path = 'caballo.mp4'\n",
        "\n",
        "# Cargar el video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# CREAR VIDEO PROCESADO (OUTPUT)\n",
        "#------------------------------------------------------------------\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "output_path = 'caballo_procesado_caballos.mp4'\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "ret = True\n",
        "#------------------------------------------------------------------\n",
        "\n",
        "# PROCESAMIENTO\n",
        "while ret:\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        # TRACKLING\n",
        "        results = model.track(frame, persist=True)\n",
        "\n",
        "        # DETECTAR SOLO CABALLOS\n",
        "        for result in results[0].boxes:\n",
        "            label = model.names[int(result.cls)]\n",
        "            if label == 'horse':\n",
        "                x1, y1, x2, y2 = map(int, result.xyxy[0])\n",
        "\n",
        "                # PINTAR DE COLOR VERDE SI EL CABALLO SE ENCUENTRA DENTRO DEL RECINTO Y DE ROJO SI ESTA FUERA\n",
        "                center_x = (x1 + x2) // 2\n",
        "                color = (0, 255, 0) if center_x < width // 2 else (0, 0, 255)\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J4z8v2nAgv_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicaci√≥n del c√≥digo** (..)"
      ],
      "metadata": {
        "id": "_a-IZzJuN4Ah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso `` width `` mide el ancho del video en p√≠xeles, y se usa para determinar si el caballo detectado est√° a la izquierda o a la derecha del video. Para poder generalizar el programa a cualquier espacio, se podr√≠a recomendar colocar la c√°mara de manera que la valla quede en la mitad del frame.\n",
        "\n",
        "No obstante, si la c√°mara tiene una posici√≥n en la que la valla no queda en el medio se puede ajustar mediante un punto de Corte Manual.\n",
        "\n",
        "__Pseudoc√≥digo:__\n",
        "```\n",
        "si centro < x = 800 -> pintar de rojo\n",
        "sino -> pintar de verde\n",
        "```\n",
        "Es decir, pasados 800 p√≠xeles desde el borde izquierdo, se utiliza el color verde.\n",
        "\n",
        "__C√≥digo:__\n",
        "```\n",
        "cutoff = 800\n",
        "color = (0, 0, 255) if center_x < cutoff else (0, 255, 0)\n",
        "```\n",
        "Para otro plano de la c√°mara se deber√° ajustar el n¬∫ de p√≠xeles para que coincida con la valla.\n"
      ],
      "metadata": {
        "id": "eXxIG9gnH7d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del video de entrada\n",
        "video_path = 'caballos.mp4'\n",
        "\n",
        "# Cargar el video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Obtener propiedades del video\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Verificar si el video se carg√≥ correctamente\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: No se pudo abrir el video.\")\n",
        "    exit()\n",
        "\n",
        "# Procesamiento del video\n",
        "while True:\n",
        "    # Leer un frame\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Fin del video o error al cargar el frame.\")\n",
        "        break\n",
        "\n",
        "    # Tracking con YOLOv8\n",
        "    results = model.track(frame, persist=True)\n",
        "\n",
        "    # Procesar detecciones\n",
        "    for result in results[0].boxes:  # Acceder a las cajas detectadas\n",
        "        label = model.names[int(result.cls)]  # Obtener el nombre de la clase\n",
        "        if label == 'horse':  # Filtrar solo caballos\n",
        "            # Coordenadas del cuadro delimitador\n",
        "            x1, y1, x2, y2 = map(int, result.xyxy[0])\n",
        "\n",
        "            # Determinar el color del cuadro seg√∫n la posici√≥n\n",
        "            center_x = (x1 + x2) // 2\n",
        "\n",
        "            # AJUSTE MANUAL DE LA DELIMITACI√ìN DE LA VALLA\n",
        "            # --------------------------------------------\n",
        "            cutoff = 800  # 900 p√≠xeles desde el borde izquierdo\n",
        "            color = (0, 0, 255) if center_x < cutoff else (0, 255, 0)\n",
        "\n",
        "            # Dibujar el cuadro y la etiqueta\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    # Mostrar el frame procesado\n",
        "    cv2.imshow('Video Procesado', frame)\n",
        "\n",
        "    # Salir con la tecla 'q'\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Liberar recursos\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print('Procesamiento de video completado.')\n"
      ],
      "metadata": {
        "id": "EsPY_UIGIY70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez controlada la posici√≥n del caballo, podemos tambi√©n deducir su velocidad."
      ],
      "metadata": {
        "id": "GYU0AhVOLQBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. VELOCIDAD - C√°lculo de la velocidad de un caballo\n"
      ],
      "metadata": {
        "id": "NW-ZZHIALdTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el √°mbito de las carreras o estudios biol√≥gicos de velocidades de cada raza de caballo es muy √∫til detectar la velocidad de un caballo dado un v√≠deo.\n",
        "\n",
        "Para ello, utilizaremos el mismo algoritmo YOLO que calcula la posici√≥n del caballo. Puesto que la velocidad es la derivada de la posici√≥n: ....\n",
        "\n",
        "\n",
        "* Se calcula la velocidad aproximada. Se debe introducir al programa la altura desde la cruz hasta el suelo del caballo. A partir del tama√±o del caballo, se utilizar√° esa medida para deducir la distancia que recorre.\n",
        "\n",
        "El tama√±o de un caballo suele ser facilmente accesible para su due√±o ya que est√° especificado en el pasaporte obligatorio del animal, de otro modo se podr√≠a medir el caballo manualmente y anotarlo."
      ],
      "metadata": {
        "id": "jJO8yhRKLnqS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLyjpzs1Mt8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicaci√≥n del c√≥digo** (..)"
      ],
      "metadata": {
        "id": "p1QKuWjSN8ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. RESULTADOS\n",
        "A continuaci√≥n se prueban los programas con varios ejemplos para verificar su fiabilidad y precisi√≥n."
      ],
      "metadata": {
        "id": "fGHkvqoLMuxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. CONCLUSIONES"
      ],
      "metadata": {
        "id": "6muNMDJANn3_"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}